{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Reinforcement Learning with OpenAI Gym\n",
    "---\n",
    "This notebook will create and test different reinforcement learning agents and environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Environment\n",
    "---\n",
    "Call `gym.make(\"environment name\")` to load a new environment.\n",
    "\n",
    "Check out the list of available environments at <https://gym.openai.com/envs/>\n",
    "\n",
    "Edit this cell to load different environments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load an environment\n",
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(4,)\nDiscrete(2)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print observation and action spaces\n",
    "print(env.observation_space)\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an Agent\n",
    "---\n",
    "\n",
    "Reset the environment before each run with `env.reset`\n",
    "\n",
    "Step forward through the environment to get new observations and rewards over time with `env.step`\n",
    "\n",
    "`env.step` takes a parameter for the action to take on this step and returns the following:\n",
    "- Observations for this step\n",
    "- Rewards earned this step\n",
    "- \"Done\", a boolean value indicating if the game is finished\n",
    "- Info - some debug information that some environments provide. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0\n9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n"
     ]
    }
   ],
   "source": [
    "# TODO Make a random agent\n",
    "games_to_play = 10\n",
    "\n",
    "for i in range(games_to_play):\n",
    "    # Reset the environment\n",
    "    obs = env.reset()\n",
    "    episode_rewards = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        # Render the environment so we can watch\n",
    "        env.render()\n",
    "        \n",
    "        # Choose a random action\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "        # Take a step in the environment with the chosen action\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_rewards += reward\n",
    "\n",
    "    # Print episode total rewards when done\n",
    "    print(episode_rewards)\n",
    "    \n",
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy Gradients\n",
    "---\n",
    "The policy gradients algorithm records gameplay over a training period, then runs the results of the actions chosen through a neural network, making successful actions that resulted in a reward more likly, and unsuccessful actions less likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Build the policy gradient neural network\n",
    "class Agent:\n",
    "    def __init__(self, num_actions, state_size):\n",
    "        \n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        \n",
    "        self.input_layer = tf.placeholder(dtype=tf.float32, shape=[None, state_size])\n",
    "        \n",
    "        # Neural net starts here\n",
    "        \n",
    "        hidden_layer = tf.layers.dense(self.input_layer, 8, activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "        \n",
    "        # Output of neural net\n",
    "        self.outputs = tf.layers.dense(hidden_layer, num_actions, activation=tf.nn.softmax)\n",
    "        self.choice = tf.argmax(self.outputs, 1)\n",
    "        \n",
    "        # Training Procedure\n",
    "        self.rewards = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None, 1], dtype=tf.int32)\n",
    "        \n",
    "        one_hot_actions = tf.one_hot(self.actions, num_actions)\n",
    "    \n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_actions, logits=self.outputs)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(self.rewards * cross_entropy)\n",
    "        \n",
    "        self.tvars = tf.trainable_variables()\n",
    "        \n",
    "        self.gradients = tf.gradients(self.loss, self.tvars)\n",
    "        \n",
    "        # Compute gradients needed to make each action more likely\n",
    "        #self.gradients = tf.gradients(loss, tf.trainable_variables())\n",
    "        #self.adjusted_gradients = self.gradients * self.rewards\n",
    "        \n",
    "        # Create a placeholder list for gradients\n",
    "        self.gradients_to_apply = []\n",
    "        for index, variable in enumerate(tf.trainable_variables()):\n",
    "            gradient_placeholder = tf.placeholder(tf.float32)\n",
    "            self.gradients_to_apply.append(gradient_placeholder)\n",
    "        \n",
    "        # Create the operation to update gradients with the gradients placeholder.\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-2)\n",
    "        self.training_op = optimizer.minimize(self.loss)\n",
    "        self.update_gradients = optimizer.apply_gradients(zip(self.gradients_to_apply, tf.trainable_variables()))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discounting Rewards\n",
    "---\n",
    "In order to determine how \"successful\" a given action is, you need to track rewards over time in the environment. You could save each frame's reward at its full value, but in reality, actions are more likely to correlate to rewards closer to the current timeframe. \"Discounting\" rewards attempts to address this problem by scaling the value of a reward down the farther "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_rate = 0.99\n",
    "\n",
    "def discount_normalize_rewards(rewards):\n",
    "    discounted_rewards = np.zeros_like(rewards)\n",
    "    total_rewards = 0\n",
    "    \n",
    "    for i in reversed(range(len(rewards))):\n",
    "        total_rewards = total_rewards * discount_rate + rewards[i]\n",
    "        discounted_rewards[i] = total_rewards\n",
    "    \n",
    "    discounted_rewards -= np.mean(discounted_rewards)\n",
    "    discounted_rewards /= np.std(discounted_rewards)\n",
    "    \n",
    "    return discounted_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Procedure\n",
    "---\n",
    "The agent will play games and record results. Every game, the gradients to apply will be calculated, and every few games they'll be averaged and applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49376717  0.5062328 ]\n[ 0.40159589  0.59840411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42864743  0.5713526 ]\n[ 0.47861791  0.52138209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42404425  0.57595575]\n[ 0.49186847  0.5081315 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 57.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48161393  0.51838613]\n[ 0.49135968  0.50864023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49678993  0.50321013]\n[ 0.39692003  0.60308003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49085739  0.50914264]\n[ 0.4845351   0.51546484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47462243  0.52537757]\n[ 0.48269576  0.51730424]\nAverage reward / 100 eps: 26.38"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n[ 0.49669814  0.50330186]\n[ 0.47595286  0.52404714]\nAverage reward / 100 eps: 26.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49218714  0.50781286]\n[ 0.28290451  0.71709549]\nAverage reward / 100 eps: 26.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49039263  0.50960743]\n[ 0.48342702  0.51657301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.46714064  0.53285939]\n[ 0.42769063  0.57230932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48123941  0.51876062]\n[ 0.38837364  0.61162639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 26.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47971219  0.52028781]\n[ 0.48814091  0.51185912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47480655  0.52519351]\nAverage reward / 100 eps: 28.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48422793  0.5157721 ]\n[ 0.48095536  0.5190447 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47287667  0.52712333]\nAverage reward / 100 eps: 25.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48388195  0.51611799]\n[ 0.48777601  0.51222402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47454944  0.52545059]\nAverage reward / 100 eps: 23.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48303679  0.51696318]\n[ 0.47057432  0.52942568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.40358469  0.59641528]\n[ 0.43298465  0.56701535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4862529   0.51374716]\n[ 0.49060404  0.50939602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 22.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47307903  0.52692097]\n[ 0.45207277  0.54792732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.46348834  0.53651166]\nAverage reward / 100 eps: 23.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48712891  0.51287109]\n[ 0.45683345  0.54316658]\nAverage reward / 100 eps: 22.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48848668  0.51151329]\n[ 0.47607961  0.52392036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.39364359  0.60635644]\nAverage reward / 100 eps: 22.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49867523  0.50132477]\n[ 0.48247951  0.51752043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 22.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48599571  0.51400429]\nAverage reward / 100 eps: 22.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4915497   0.50845033]\n[ 0.50413376  0.49586624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48329309  0.51670688]\n[ 0.46611023  0.53388983]\nAverage reward / 100 eps: 21.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49729681  0.50270319]\nAverage reward / 100 eps: 23.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48806301  0.51193696]\n[ 0.49220493  0.50779516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48006725  0.51993275]\n[ 0.41571328  0.58428675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 25.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48546916  0.5145309 ]\n[ 0.47082841  0.52917159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47334036  0.52665967]\nAverage reward / 100 eps: 23.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48473904  0.51526099]\n[ 0.45840296  0.54159713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 23.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48428464  0.51571536]\n[ 0.514503    0.48549706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5000059   0.49999416]\nAverage reward / 100 eps: 23.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48141244  0.51858765]\n[ 0.4651683  0.5348317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 22.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49440181  0.50559813]\n[ 0.55707085  0.44292912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 20.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51009041  0.48990965]\n[ 0.52820629  0.47179374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49397412  0.50602585]\n[ 0.52511609  0.47488388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.59173948  0.40826052]\nAverage reward / 100 eps: 19.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.50521851  0.49478143]\n[ 0.55783474  0.44216532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 18.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.50367761  0.49632239]\n[ 0.49056819  0.50943178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52202463  0.47797534]\nAverage reward / 100 eps: 20.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49826568  0.50173438]\n[ 0.48453847  0.5154615 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.53834438  0.46165556]\n[ 0.51981306  0.48018694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.45604038  0.54395962]\nAverage reward / 100 eps: 19.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51079959  0.48920041]\n[ 0.48618537  0.51381457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 17.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.53281921  0.46718079]\nAverage reward / 100 eps: 17.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.55051935  0.44948065]\n[ 0.49857154  0.50142843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 17.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56068444  0.43931556]\n[ 0.72581023  0.27418986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91167986  0.08832011]\nAverage reward / 100 eps: 15.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.60441458  0.39558542]\n[ 0.76521832  0.23478171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 14.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63757962  0.36242035]\n[ 0.62910497  0.370895  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.92422724  0.07577282]\nAverage reward / 100 eps: 14.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63266748  0.36733252]\nAverage reward / 100 eps: 13.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.64921564  0.35078436]\n[ 0.56591034  0.43408963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99464059  0.00535939]\nAverage reward / 100 eps: 12.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68399847  0.3160015 ]\nAverage reward / 100 eps: 11.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70409727  0.2959027 ]\nAverage reward / 100 eps: 12.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.69734466  0.30265531]\n[ 0.99841654  0.00158342]\nAverage reward / 100 eps: 11.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7499761  0.2500239]\nAverage reward / 100 eps: 11.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77017087  0.2298291 ]\nAverage reward / 100 eps: 10.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80633026  0.19366971]\n[ 0.9980343  0.0019657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 10.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7960816   0.20391843]\n[ 0.98890746  0.01109258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 10.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8422209   0.15777902]\n[ 0.9955017   0.00449825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward / 100 eps: 9.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.83379865  0.1662014 ]\nAverage reward / 100 eps: 10.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85919887  0.1408011 ]\n[  9.99923944e-01   7.61058182e-05]\nAverage reward / 100 eps: 10.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87603766  0.12396238]\nAverage reward / 100 eps: 10.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86152053  0.13847946]\nAverage reward / 100 eps: 10.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87846875  0.12153124]\nAverage reward / 100 eps: 9.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.89751655  0.10248343]\nAverage reward / 100 eps: 9.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88337511  0.11662486]\nAverage reward / 100 eps: 9.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90532869  0.09467133]\nAverage reward / 100 eps: 9.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91390443  0.08609564]\nAverage reward / 100 eps: 9.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91249961  0.08750039]\nAverage reward / 100 eps: 9.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.92368442  0.07631559]\nAverage reward / 100 eps: 9.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9388783   0.06112168]\nAverage reward / 100 eps: 9.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.931705    0.06829496]\nAverage reward / 100 eps: 9.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.94405955  0.05594045]\nAverage reward / 100 eps: 9.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.94142902  0.05857096]\nAverage reward / 100 eps: 9.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95410866  0.0458914 ]\nAverage reward / 100 eps: 9.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95078039  0.0492196 ]\nAverage reward / 100 eps: 9.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95953959  0.04046037]\nAverage reward / 100 eps: 9.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95054877  0.04945129]\nAverage reward / 100 eps: 9.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95133364  0.04866631]\nAverage reward / 100 eps: 9.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96152264  0.03847732]\nAverage reward / 100 eps: 9.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95860666  0.04139328]\nAverage reward / 100 eps: 9.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95470303  0.04529693]\nAverage reward / 100 eps: 9.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9623844   0.03761559]\nAverage reward / 100 eps: 9.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95803171  0.04196827]\nAverage reward / 100 eps: 9.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95972621  0.04027372]\nAverage reward / 100 eps: 9.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96200109  0.0379989 ]\nAverage reward / 100 eps: 9.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9657222   0.03427781]\nAverage reward / 100 eps: 9.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97512507  0.02487496]\nAverage reward / 100 eps: 9.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97546482  0.02453522]\nAverage reward / 100 eps: 9.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97690135  0.02309862]\nAverage reward / 100 eps: 9.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97193313  0.02806693]\nAverage reward / 100 eps: 9.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97047698  0.02952297]\nAverage reward / 100 eps: 9.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97221464  0.02778543]\nAverage reward / 100 eps: 9.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97247249  0.02752755]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97459126  0.02540875]\nAverage reward / 100 eps: 9.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97238296  0.02761702]\nAverage reward / 100 eps: 9.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96957153  0.03042841]\nAverage reward / 100 eps: 9.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97336018  0.02663975]\n[  1.00000000e+00   2.50047982e-08]\nAverage reward / 100 eps: 9.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97677886  0.02322118]\nAverage reward / 100 eps: 9.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97822011  0.02177992]\nAverage reward / 100 eps: 9.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97893196  0.02106798]\nAverage reward / 100 eps: 9.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97918773  0.02081227]\nAverage reward / 100 eps: 9.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98115104  0.018849  ]\nAverage reward / 100 eps: 9.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98082584  0.01917412]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98238498  0.01761502]\nAverage reward / 100 eps: 9.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98205066  0.01794934]\nAverage reward / 100 eps: 9.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98418367  0.01581634]\nAverage reward / 100 eps: 9.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98411316  0.01588688]\nAverage reward / 100 eps: 9.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97941691  0.02058308]\nAverage reward / 100 eps: 9.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98050469  0.01949525]\nAverage reward / 100 eps: 9.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9855665   0.01443349]\nAverage reward / 100 eps: 9.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98672163  0.01327839]\nAverage reward / 100 eps: 9.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98189878  0.0181012 ]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98332477  0.01667516]\nAverage reward / 100 eps: 9.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9860298   0.01397026]\nAverage reward / 100 eps: 9.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98328745  0.01671259]\nAverage reward / 100 eps: 9.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98837715  0.01162282]\nAverage reward / 100 eps: 9.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98653644  0.01346356]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99047559  0.00952444]\nAverage reward / 100 eps: 9.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98815966  0.01184037]\nAverage reward / 100 eps: 9.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98521233  0.01478766]\nAverage reward / 100 eps: 9.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98720086  0.01279917]\nAverage reward / 100 eps: 9.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98940396  0.01059607]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98592895  0.01407109]\nAverage reward / 100 eps: 9.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98868549  0.01131449]\nAverage reward / 100 eps: 9.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98955017  0.0104498 ]\nAverage reward / 100 eps: 9.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98547947  0.01452051]\nAverage reward / 100 eps: 9.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.988518    0.01148202]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98801684  0.01198311]\nAverage reward / 100 eps: 9.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98709548  0.01290449]\nAverage reward / 100 eps: 9.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98866755  0.0113324 ]\nAverage reward / 100 eps: 9.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99074101  0.00925897]\nAverage reward / 100 eps: 9.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98678708  0.01321291]\nAverage reward / 100 eps: 9.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98671407  0.01328589]\nAverage reward / 100 eps: 9.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98896796  0.01103206]\nAverage reward / 100 eps: 9.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99239963  0.0076004 ]\nAverage reward / 100 eps: 9.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98829275  0.01170726]\nAverage reward / 100 eps: 9.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99029213  0.00970785]\nAverage reward / 100 eps: 9.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99076957  0.00923049]\nAverage reward / 100 eps: 9.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9913584   0.00864156]\nAverage reward / 100 eps: 9.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98924482  0.01075525]\nAverage reward / 100 eps: 9.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98957217  0.01042787]\nAverage reward / 100 eps: 9.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99036729  0.00963277]\nAverage reward / 100 eps: 9.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99232703  0.00767295]\nAverage reward / 100 eps: 9.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99065256  0.00934748]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99242002  0.00757995]\nAverage reward / 100 eps: 9.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99091816  0.00908178]\n[  1.00000000e+00   1.32687761e-09]\nAverage reward / 100 eps: 9.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99253041  0.00746962]\nAverage reward / 100 eps: 9.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99067229  0.00932764]\nAverage reward / 100 eps: 9.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99328351  0.00671646]\nAverage reward / 100 eps: 9.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99346381  0.00653612]\nAverage reward / 100 eps: 9.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99181867  0.00818131]\nAverage reward / 100 eps: 9.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99395162  0.00604832]\nAverage reward / 100 eps: 9.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99282503  0.00717499]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99403518  0.00596484]\nAverage reward / 100 eps: 9.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9928      0.00719996]\nAverage reward / 100 eps: 9.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99033922  0.00966074]\nAverage reward / 100 eps: 9.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99374074  0.0062592 ]\nAverage reward / 100 eps: 9.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99221933  0.00778067]\nAverage reward / 100 eps: 9.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99198443  0.00801565]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99483889  0.00516113]\nAverage reward / 100 eps: 9.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9927845   0.00721547]\nAverage reward / 100 eps: 9.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.992652    0.00734807]\nAverage reward / 100 eps: 9.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99381626  0.00618379]\nAverage reward / 100 eps: 9.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99434537  0.00565455]\nAverage reward / 100 eps: 9.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99461937  0.00538064]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99273539  0.00726457]\nAverage reward / 100 eps: 9.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99484694  0.00515309]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99227905  0.00772093]\nAverage reward / 100 eps: 9.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99503088  0.00496913]\nAverage reward / 100 eps: 9.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99385035  0.00614965]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99511755  0.00488243]\nAverage reward / 100 eps: 9.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99368143  0.00631859]\nAverage reward / 100 eps: 9.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99551398  0.00448602]\nAverage reward / 100 eps: 9.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99361742  0.00638261]\nAverage reward / 100 eps: 9.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99225664  0.00774333]\nAverage reward / 100 eps: 9.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9951362   0.00486385]\nAverage reward / 100 eps: 9.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99448377  0.00551623]\nAverage reward / 100 eps: 9.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99348998  0.00651002]\nAverage reward / 100 eps: 9.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99529487  0.00470517]\nAverage reward / 100 eps: 9.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9947108   0.00528915]\nAverage reward / 100 eps: 9.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99471855  0.00528141]\nAverage reward / 100 eps: 9.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99385554  0.00614442]\nAverage reward / 100 eps: 9.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99426419  0.0057358 ]\nAverage reward / 100 eps: 9.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99327761  0.00672235]\nAverage reward / 100 eps: 9.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99509227  0.00490768]\nAverage reward / 100 eps: 9.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99488139  0.00511856]\nAverage reward / 100 eps: 9.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99382341  0.00617663]\nAverage reward / 100 eps: 9.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99575365  0.00424638]\nAverage reward / 100 eps: 9.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99391335  0.00608665]\nAverage reward / 100 eps: 9.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99537438  0.00462559]\nAverage reward / 100 eps: 9.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99592233  0.00407761]\nAverage reward / 100 eps: 9.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99593532  0.0040647 ]\nAverage reward / 100 eps: 9.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99517411  0.00482586]\nAverage reward / 100 eps: 9.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99447292  0.00552703]\nAverage reward / 100 eps: 9.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99573046  0.00426959]\nAverage reward / 100 eps: 9.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99496788  0.00503214]\nAverage reward / 100 eps: 9.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99532372  0.00467625]\nAverage reward / 100 eps: 9.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99563438  0.00436556]\nAverage reward / 100 eps: 9.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99361658  0.00638338]\nAverage reward / 100 eps: 9.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99475515  0.0052449 ]\nAverage reward / 100 eps: 9.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99680316  0.00319683]\nAverage reward / 100 eps: 9.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99472284  0.00527712]\nAverage reward / 100 eps: 9.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99574846  0.00425151]\nAverage reward / 100 eps: 9.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9967379   0.00326215]\nAverage reward / 100 eps: 9.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99475765  0.00524236]\nAverage reward / 100 eps: 9.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99605453  0.00394542]\nAverage reward / 100 eps: 9.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99516064  0.00483942]\nAverage reward / 100 eps: 9.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99519759  0.00480239]\nAverage reward / 100 eps: 9.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99671161  0.00328836]\nAverage reward / 100 eps: 9.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99677867  0.00322138]\nAverage reward / 100 eps: 9.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99655199  0.00344795]\nAverage reward / 100 eps: 9.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99645209  0.00354794]\nAverage reward / 100 eps: 9.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99503243  0.00496752]\nAverage reward / 100 eps: 9.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99571061  0.00428933]\nAverage reward / 100 eps: 9.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99612021  0.00387985]\nAverage reward / 100 eps: 9.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99587387  0.00412612]\n[  1.00000000e+00   1.64897082e-10]\nAverage reward / 100 eps: 9.41\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "agent = Agent(2,4)\n",
    "\n",
    "training_episodes = 20000\n",
    "max_steps_per_episode = 10000\n",
    "episode_batch_size = 5\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    batch_history = []\n",
    "    \n",
    "    total_episode_rewards = []\n",
    "    \n",
    "    # Create a buffer of 0'd gradients\n",
    "    gradient_buffer = sess.run(agent.tvars)\n",
    "    for index, gradient in enumerate(gradient_buffer):\n",
    "        gradient_buffer[index] = gradient * 0\n",
    "\n",
    "    for episode in range(training_episodes):\n",
    "\n",
    "        state = env.reset()\n",
    "        \n",
    "        episode_history = []\n",
    "        episode_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps_per_episode):\n",
    "            \n",
    "            if episode % 100 == 0:\n",
    "                env.render()\n",
    "            \n",
    "            # Get weights for each action\n",
    "            action_probabilities = sess.run(agent.outputs, feed_dict={agent.input_layer: [state]})\n",
    "            if( episode % 100 == 0 and step % 10 == 0):\n",
    "                print(action_probabilities[0])\n",
    "            action_choice = np.random.choice(range(2), p=action_probabilities[0])\n",
    "            \n",
    "            state_next, reward, done, _ = env.step(action_choice)\n",
    "            episode_history.append([state, action_choice, reward, state_next])\n",
    "            state = state_next\n",
    "            \n",
    "            episode_rewards += reward\n",
    "            \n",
    "            if done:\n",
    "                total_episode_rewards.append(episode_rewards)\n",
    "                episode_history = np.array(episode_history)\n",
    "                episode_history[:,2] = discount_normalize_rewards(episode_history[:,2])\n",
    "                \n",
    "                ep_gradients = sess.run(agent.gradients, feed_dict={agent.input_layer: np.vstack(episode_history[:, 0]),\n",
    "                                                                    agent.actions: np.vstack(episode_history[:, 1]),\n",
    "                                                                    agent.rewards: np.vstack(episode_history[:, 2])})\n",
    "                # add the gradients to the grad buffer:\n",
    "                for index, gradient in enumerate(ep_gradients):\n",
    "                    gradient_buffer[index] += gradient\n",
    "                    \n",
    "                #Record episode events to the batch\n",
    "                #batch_history.extend(episode_history)\n",
    "                break\n",
    "            \n",
    "        if episode % episode_batch_size == 0:\n",
    "            \n",
    "            if episode % 100 == 0:\n",
    "                print(\"Average reward / 100 eps: \" + str(np.mean(total_episode_rewards[-100:])))\n",
    "            # Run a training step with the batch we've collected\n",
    "            #batch_history = np.array(batch_history)\n",
    "            #batch_states = batch_history[:,0]\n",
    "            #batch_actions = batch_history[:,1]\n",
    "            #batch_rewards = batch_history[:,2]\n",
    "            \n",
    "            feed_dict_gradients = dict(zip(agent.gradients_to_apply, gradient_buffer))\n",
    "            \n",
    "            sess.run(agent.update_gradients, feed_dict=feed_dict_gradients)\n",
    "            \n",
    "            for index, gradient in enumerate(gradient_buffer):\n",
    "                gradient_buffer[index] = gradient * 0\n",
    "            \n",
    "            batch_history = []\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
